{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 449 slices -> 16 chunks in each chunk, slices are represented as groups, in each -> (3, N) \n",
    "# (0, N) -> flat \n",
    "# (1, N) -> ID\n",
    "# (2, N) -> ?\n",
    "# (449, 999, 999)\n",
    "# ex. nchuncks = 500/100 = 5, is that true?\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import math\n",
    "import mahotas\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "import lxml\n",
    "import lxml.etree\n",
    "import sys\n",
    "sys.path.append('/Users/haneen')\n",
    "import cv2\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir \"/Users/haneen/Downloads/hdf5_BigStack/ids\"\n",
      "0\n",
      "mkdir \"/Users/haneen/Downloads/hdf5_BigStack/ids/tiles\"\n",
      "0\n",
      "Found 1039 input images in /Users/haneen/Downloads/BigStack/*.png\n",
      "/Users/haneen/Downloads/BigStack/Labels0001.png\n",
      "original_ids.shape: (4096, 4096)\n",
      "[0 1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a66cf92442c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moriginal_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpixel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpixel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0mfiltered_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# number of chunks = # original slices/ #compressed slices\n",
    "def mkdir_safe( dir_to_make ):\n",
    "    if not os.path.exists( dir_to_make ):\n",
    "        execute_string = 'mkdir ' + '\"' + dir_to_make + '\"'\n",
    "        print execute_string\n",
    "        print os.system( execute_string )\n",
    "\n",
    "\n",
    "def load_id_image ( file_path ):\n",
    "    ids = np.int32( np.array( mahotas.imread( file_path ) ) )\n",
    "    # ids.shape = (999, 999, 4)\n",
    "    # ids[0][0] = [  0   0   0 255]\n",
    "    if len( ids.shape ) == 3:\n",
    "        ids = ids[ :, :, 2 ] + ids[ :, :, 1 ] * 2**8 + ids[ :, :, 0 ] * 2**16\n",
    "    else:\n",
    "        # Read from pipeline format\n",
    "        ids = ids.transpose() - 1\n",
    "    return ids\n",
    "\n",
    "    \n",
    "original_input_ids_path       = '../input/segmentation'\n",
    "#output_path                   = '../temp/mojo'\n",
    "\n",
    "input_file_format             = 'png'\n",
    "\n",
    "output_ids_path                = output_path + '/ids'\n",
    "mkdir_safe( output_ids_path  )\n",
    "\n",
    "output_tile_ids_path           = output_ids_path + '/tiles'\n",
    "mkdir_safe( output_tile_ids_path )\n",
    "\n",
    "# count how many input images are loaded\n",
    "input_search_string  = original_input_ids_path + '/*.' + input_file_format # -> ../input/segmentation/*.png\n",
    "files                = sorted( glob.glob( input_search_string ) )\n",
    "print \"Found {0} input images in {1}\".format( len(files), input_search_string )\n",
    "nimages_to_process            = len(files) \n",
    "\n",
    "if len(files) > 0:\n",
    "    id_max               = 0;\n",
    "    id_counts            = np.zeros( 0, dtype=np.int64 );\n",
    "    tile_index_z         = 0\n",
    "    K                    = 10\n",
    "    #fout = open(\"../temp/mojo/ids/tiles/chunkMap.txt\", \"w\")\n",
    "#     fout = open(\"/Users/haneen/Downloads/hdf5_BigStack/ids/tiles/chunkMap.txt\", \"w\")\n",
    "    \n",
    "    i, j = 0, 0\n",
    "    s = 0\n",
    "    MAX = 0\n",
    "    D = 3 # dimension\n",
    "    voxelsPerChunk = 0\n",
    "    for file in files:  \n",
    "        print file     \n",
    "        original_input_ids_name = file\n",
    "        original_ids = load_id_image( original_input_ids_name )\n",
    "        ( original_image_num_pixels_x, original_image_num_pixels_y ) = original_ids.shape\n",
    "        print \"original_ids.shape: \" + str(original_ids.shape) #(999, 999)\n",
    "        print np.unique(original_ids)\n",
    "        N = 0\n",
    "        filtered_ids, filtered_index = [], []\n",
    "        for row in original_ids:\n",
    "            for pixel in row:\n",
    "                if (pixel):    \n",
    "                    filtered_ids.append(pixel)\n",
    "                    filtered_index.append(N)\n",
    "                \n",
    "                N = N + 1                    \n",
    "        print np.unique(filtered_ids)\n",
    "\n",
    "#         # open the hdf5 file every offset, open a file, and write to it the chunk of slices\n",
    "#         if (tile_index_z%K == 0):\n",
    "#             if (voxelsPerChunk > MAX):\n",
    "#                 MAX = voxelsPerChunk\n",
    "#             voxelsPerChunk = 0\n",
    "#             if (tile_index_z + K > nimages_to_process):\n",
    "#                 print \"HERE\"\n",
    "#                 i = j\n",
    "#                 j = nimages_to_process\n",
    "#                 print str(i) + \" \" + str(j)\n",
    "#                 fout.write(str(i) + \" \" + str(j) + \"\\n\")\n",
    "#                 print \"tile_index_z: \" + str(tile_index_z)\n",
    "#                 current_tile_ids_name    = output_tile_ids_path    + '/%d' % ( s ) + '.h5'\n",
    "#                 group = 0\n",
    "#                 s = s + 1\n",
    "#                 print current_tile_ids_name\n",
    "#                 hdf5             = h5py.File( current_tile_ids_name, 'w' )\n",
    "#             else:\n",
    "#                 print \"tile_index_z: \" + str(tile_index_z)\n",
    "#                 current_tile_ids_name    = output_tile_ids_path    + '/%d' % ( s ) + '.h5'\n",
    "#                 group = 0\n",
    "#                 s = s + 1\n",
    "#                 print current_tile_ids_name\n",
    "#                 hdf5             = h5py.File( current_tile_ids_name, 'w' )\n",
    "\n",
    "#                 ########## chunkMapping.txt ###############\n",
    "#                 # (i, j), i=j, j = i+K, init: i = 0, j = 0 \n",
    "#                 i = j\n",
    "#                 j = i + K\n",
    "#                 print str(i) + \" \" + str(j)\n",
    "#                 fout.write(str(i) + \" \" + str(j) + \"\\n\")\n",
    "        \n",
    "#         N = original_image_num_pixels_x * original_image_num_pixels_x\n",
    "\n",
    "#         tile_index_z = tile_index_z + 1\n",
    "#         D = 3\n",
    "#         if (len(filtered_ids) <= 0):\n",
    "#             print \"SKIPED!\"\n",
    "#             D = 1\n",
    "#             filtered_index.append(0)\n",
    "            \n",
    "        \n",
    "#         voxelsPerChunk += len(filtered_ids)\n",
    "            \n",
    "#         group_name = '%d' % (group) \n",
    "#         group = group + 1\n",
    "#         dataset = hdf5.get(\"/\").create_dataset(group_name, (D , len(filtered_index)))\n",
    "#         print \"Dataset shape: \" + str(dataset.shape) + \", Dataset type: \" + str(dataset.dtype)\n",
    "\n",
    "#         print \"Writing: \" + str(tile_index_z)\n",
    "#         if (D == 1):\n",
    "#             dataset[0,:]  = 0\n",
    "#             continue\n",
    "        \n",
    "#         # flattened ij -> index = x + y * WIDTH\n",
    "#         # original_ids[d] -> d = 1 (y) , d = 0 (x)\n",
    "#         dataset[0, :]  = filtered_index\n",
    "#         # object id\n",
    "#         # filtered_ids, filtered_index\n",
    "#         dataset[1, :] = filtered_ids\n",
    "#         # birth?\n",
    "#         dataset[2, :] = 1\n",
    "\n",
    "         \n",
    "#         if (tile_index_z%(K) == 0):\n",
    "#             hdf5.close()\n",
    "            \n",
    "#         if tile_index_z > nimages_to_process:\n",
    "#             print str(tile_index_z) + \" >= \" + str(nimages_to_process)\n",
    "#             break\n",
    "                \n",
    "#     fout.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#index_counter.update(index_list)\n",
    "#print index_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # unflatten the data. collect the chunks into one big chunk, with z = 499 slices, x=999 (width), y=999 (hight)\n",
    "# SLICES = 449\n",
    "# h5dir = '../temp/mojo/ids/tiles/*.h5'\n",
    "# h5files                = sorted( glob.glob( h5dir ) )\n",
    "# slices_xy = [0] * SLICES\n",
    "# count = 0\n",
    "# index_list = []\n",
    "# index_counter = Counter()\n",
    "# for file in h5files:\n",
    "#     with h5py.File(file, 'r') as hf:\n",
    "#         # i want them sorted. from 0 to max chunk\n",
    "#         # print file, 'List of arrays in this file: \\n', hf.keys()\n",
    "#         for key in hf.keys():\n",
    "#             data = hf.get(key)\n",
    "#             np_data = np.array(data)\n",
    "#             i = file.split('/')[-1][:-3]\n",
    "#             index = int(i) * 10 + int(key)\n",
    "#             slices_xy[index] = np_data\n",
    "#             count = count + 1\n",
    "#             index_list.append(index)\n",
    "# count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 999)\n"
     ]
    }
   ],
   "source": [
    "# # iterate over the slices in order and reconstruct one hdf5 file\n",
    "# import math\n",
    "# i = 0\n",
    "# XY = np.zeros((999, 999), dtype='int32')\n",
    "# print XY.shape\n",
    "# XYZ = []\n",
    "# hdf5 = h5py.File( 'slices_unflattened.h5', 'w' )\n",
    "# dataset = hdf5.get(\"/\").create_dataset('channel10', (999, 999, 449))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haneen/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/IPython/kernel/__main__.py:19: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# for slice in slices_xy:\n",
    "#     if (len(slice) == 1):\n",
    "#         continue\n",
    "        \n",
    "   \n",
    "#     xy = slice[0]    \n",
    "#     Ids = slice[1]\n",
    "#     # flat = x * width + y\n",
    "#     # unflattened x = floor(flattened / width)?\n",
    "#     # unflatteded y = flattened - x * width\n",
    "#     # 0 1 2 3 4 -> 0, 1, 2, 3, 4 -> \n",
    "#     # 0 1 2 3 4 -> 5, 6, 7, 8, 9\n",
    "#     # 0 1 2 3 4 -> 10, ...\n",
    "#     # 0 1 2 3 4\n",
    "#     for index in range(len(xy)):\n",
    "#         flat_xy = xy[index]\n",
    "#         x = math.floor(flat_xy/999)\n",
    "#         y = flat_xy - x * 999\n",
    "#         XY[x][y] = Ids[index]\n",
    "        \n",
    "#     # write this slice to hdf5 file\n",
    "#     dataset[:, :, i] = XY\n",
    "#     i = i + 1 \n",
    "\n",
    "# hdf5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(slices_xy):  449\n",
      "each entry has  3  entries.\n",
      "1- xy flattended, 2- ids, 3- garbig\n",
      "Each entry has variying number of flattened xys 674231\n"
     ]
    }
   ],
   "source": [
    "# # slices_xy\n",
    "# print 'len(slices_xy): ', len(slices_xy)\n",
    "# print 'each entry has ', len(slices_xy[0]), ' entries.'\n",
    "# print '1- xy flattended, 2- ids, 3- garbig'\n",
    "# print 'Each entry has variying number of flattened xys', len(slices_xy[10][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hdf5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
